{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T11:58:51.061011Z",
     "start_time": "2025-04-17T11:58:48.543249Z"
    }
   },
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Scripts\\GANalyze\\pytorch\\assessors')\n",
    "\n",
    "from emonet import EmoNet, emonet\n",
    "\n",
    "# Example usage of EmoNet\n",
    "model, input_transform, output_transform = emonet(tencrop=False)\n",
    "print(\"Model loaded successfully.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\scripts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sOrOush\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sOrOush\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Scripts\\GANalyze\\pytorch\\assessors\\emonet.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  parameters = torch.load(model_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:58:56.472153Z",
     "start_time": "2025-04-17T11:58:56.136687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import socket\n",
    "import argparse\n",
    "import json\n",
    "import subprocess\n",
    "from contextlib import contextmanager\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sub = 1\n",
    "bs = 30"
   ],
   "id": "f8160cba467a9deb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:58:59.001609Z",
     "start_time": "2025-04-17T11:58:58.653202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Scripts\\GANalyze\\pytorch\\assessors')\n",
    "\n",
    "import emonet\n",
    "\n",
    "assessor_in = 'emonet'\n",
    "assessor_elements = getattr(emonet, assessor_in)(False)\n",
    "if isinstance(assessor_elements, tuple):\n",
    "    assessor = assessor_elements[0]\n",
    "    input_transform = assessor_elements[1]\n",
    "    output_transform = assessor_elements[2]\n",
    "else:\n",
    "    assessor = assessor_elements\n",
    "\n",
    "    def input_transform(x):\n",
    "        return x  # identity, no preprocessing\n",
    "\n",
    "    def output_transform(x):\n",
    "        return x  # identity, no postprocessing\n",
    "\n",
    "if hasattr(assessor, 'parameters'):\n",
    "    for p in assessor.parameters():\n",
    "        p.requires_grad = False\n",
    "        assessor.eval()\n",
    "        assessor.to()"
   ],
   "id": "e177100ab91b2aed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sOrOush\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sOrOush\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Scripts\\GANalyze\\pytorch\\assessors\\emonet.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  parameters = torch.load(model_path, map_location='cpu')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:00.096898Z",
     "start_time": "2025-04-17T11:59:00.093013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_images_prep_assessor(data_path):\n",
    "    data = np.load(data_path).astype(np.uint8)\n",
    "    dim0, dim1, dim2, dim3 = data.shape[0], 256, 256, 3\n",
    "    data_tensor = torch.empty(dim0, dim3, dim1, dim2)\n",
    "\n",
    "    for idx in range(len(data)):\n",
    "            img = Image.fromarray(data[idx])\n",
    "            img = T.functional.resize(img, (256, 256))\n",
    "            img_tensor = T.functional.to_tensor(img)  # Automatically converts to float and scales to [0, 1]\n",
    "\n",
    "            # Store the normalized image tensor\n",
    "            data_tensor[idx] = img_tensor\n",
    "\n",
    "    return data_tensor"
   ],
   "id": "9066df69f7593348",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:01.620701Z",
     "start_time": "2025-04-17T11:59:01.616219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "def natural_sort_key(s):\n",
    "    return [int(c) if c.isdigit() else c.lower() for c in re.split('(\\d+)', s)]\n",
    "\n",
    "def test_images_prep_assessor_CLIP(image_folder, target_size=(256, 256)):\n",
    "    data_tensor = []\n",
    "\n",
    "    # Get all image files and sort them\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    image_files.sort(key=natural_sort_key)\n",
    "\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        transform = T.Compose([\n",
    "            T.Resize(target_size),\n",
    "            T.ToTensor()  # This converts to float and scales to [0, 1]\n",
    "        ])\n",
    "\n",
    "        img_tensor = transform(img)\n",
    "        data_tensor.append(img_tensor)\n",
    "\n",
    "    return torch.stack(data_tensor)"
   ],
   "id": "3bf5e12232c83627",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\sOrOush\\AppData\\Local\\Temp\\ipykernel_42324\\1355969087.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  return [int(c) if c.isdigit() else c.lower() for c in re.split('(\\d+)', s)]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:03.830797Z",
     "start_time": "2025-04-17T11:59:03.828084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emonet_res = {\n",
    "    'nsdgeneral_degree1': [],\n",
    "    'nsdgeneral_degree2': [],\n",
    "    'nsdgeneral_degree3': [],\n",
    "    'nsdgeneral_degree4': [],\n",
    "    'Default_degree1': [],\n",
    "    'Default_degree2': [],\n",
    "    'Default_degree3': [],\n",
    "    'Default_degree4': [],\n",
    "    'Auditory_degree1': [],\n",
    "    'Auditory_degree2': [],\n",
    "    'Auditory_degree3': [],\n",
    "    'Auditory_degree4': []\n",
    "}"
   ],
   "id": "1b40d7fb7259f0d4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:42.537982Z",
     "start_time": "2025-04-17T11:59:06.913030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## real_img\n",
    "image_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\results\\00_Original_Images\"\n",
    "test_tensor = test_images_prep_assessor_CLIP(image_path)\n",
    "# Reshape while keeping the last 3 dimensions\n",
    "test_im = test_tensor.view(-1, *test_tensor.shape[-3:])\n",
    "\n",
    "#------  Apply the transformations and assess\n",
    "score = assessor(test_im)\n",
    "emonet_res['real_img'] = [s.detach().numpy()[0] for s in score]\n",
    "print(\"====Real Done!====\")\n"
   ],
   "id": "d435fd57b254e7c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Real Done!====\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:56.162739Z",
     "start_time": "2025-04-17T11:59:56.154607Z"
    }
   },
   "cell_type": "code",
   "source": "emonet_res.keys()",
   "id": "d0a466a97bade9ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nsdgeneral_degree1', 'nsdgeneral_degree2', 'nsdgeneral_degree3', 'nsdgeneral_degree4', 'Default_degree1', 'Default_degree2', 'Default_degree3', 'Default_degree4', 'Auditory_degree1', 'Auditory_degree2', 'Auditory_degree3', 'Auditory_degree4', 'real_img'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:59:58.914272Z",
     "start_time": "2025-04-17T11:59:58.910577Z"
    }
   },
   "cell_type": "code",
   "source": "emonet_res_keys = list(emonet_res.keys())",
   "id": "3823d9acb08e656c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T12:07:41.262661Z",
     "start_time": "2025-04-17T12:00:02.743786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the base directory where the \"VDVAE\" results are stored\n",
    "base_dir = r\"C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\results\\generated images\\VDVAE\"\n",
    "\n",
    "\n",
    "# Iterate over groups and degrees to build keys and load images\n",
    "for group in groups:\n",
    "    for degree in degrees:\n",
    "        # Construct a unique key, e.g., \"nsdgeneral_degree1\"\n",
    "        key = f\"{group}_degree{degree}\"\n",
    "        # base_dir/<group>/degree<degree>/subj01\n",
    "        image_path = os.path.join(base_dir, group, f\"degree{degree}\", \"subj01\")\n",
    "        test_tensor = test_images_prep_assessor_CLIP(image_path)\n",
    "        test_im = test_tensor.view(-1, *test_tensor.shape[-3:])\n",
    "        score = assessor(test_im)\n",
    "        emonet_res[key] = [s.detach().numpy()[0] for s in score]\n",
    "        print(f\"{key} is done.\")\n"
   ],
   "id": "95f408c9abfda205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsdgeneral_degree1 is done.\n",
      "nsdgeneral_degree2 is done.\n",
      "nsdgeneral_degree3 is done.\n",
      "nsdgeneral_degree4 is done.\n",
      "Default_degree1 is done.\n",
      "Default_degree2 is done.\n",
      "Default_degree3 is done.\n",
      "Default_degree4 is done.\n",
      "Auditory_degree1 is done.\n",
      "Auditory_degree2 is done.\n",
      "Auditory_degree3 is done.\n",
      "Auditory_degree4 is done.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T12:16:28.399507Z",
     "start_time": "2025-04-17T12:16:28.337813Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming your dictionary is stored in 'emonet_res'\n",
    "file_path = r'C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\results\\assessor_results\\emonet_res.pkl'\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(emonet_res, file)\n"
   ],
   "id": "1b8c4a0623339a8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
