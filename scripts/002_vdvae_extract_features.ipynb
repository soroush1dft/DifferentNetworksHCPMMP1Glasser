{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T14:29:09.503391Z",
     "start_time": "2025-04-08T14:29:04.646540Z"
    }
   },
   "source": [
    "path_model = 'C:/Users/sOrOush/SoroushProjects/02_Linearity_Project/02_Models/vdvae'\n",
    "\n",
    "import sys\n",
    "sys.path.append(path_model)\n",
    "# Check if the directory has been added\n",
    "print(\"Current sys.path:\", sys.path)\n",
    "\n",
    "# Attempt to import the module\n",
    "try:\n",
    "    from model_utils import *\n",
    "    print(\"Module model_utils successfully imported.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing the module: {e}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sys.path: ['C:\\\\Users\\\\sOrOush\\\\SoroushProjects\\\\14_CLIP_Ozcelic', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python-ce\\\\helpers\\\\pydev', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\python312.zip', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\DLLs', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question', '', 'C:\\\\Users\\\\sOrOush\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'C:/Users/sOrOush/SoroushProjects/02_Linearity_Project/02_Models/vdvae']\n",
      "Module model_utils successfully imported.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:31:58.364959Z",
     "start_time": "2025-04-08T14:31:58.358302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "#from mpi4py import MPI\n",
    "import socket\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from hps import Hyperparams, parse_args_and_update_hparams, add_vae_arguments\n",
    "from utils import (logger,\n",
    "                   local_mpi_rank,\n",
    "                   mpi_size,\n",
    "                   maybe_download,\n",
    "                   mpi_rank)\n",
    "from data import mkdir_p\n",
    "from contextlib import contextmanager\n",
    "import torch.distributed as dist\n",
    "#from apex.optimizers import FusedAdam as AdamW\n",
    "from vae import VAE\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel\n",
    "from train_helpers import restore_params\n",
    "from image_utils import *\n",
    "from model_utils import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "\n",
    "import argparse"
   ],
   "id": "37e718f0584f9778",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:32:11.683467Z",
     "start_time": "2025-04-08T14:32:11.679253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the script is running in a Jupyter Notebook\n",
    "if 'ipykernel' in sys.modules:\n",
    "    # Default values for Jupyter Notebook\n",
    "    sub = 1  # You can specify the desired default value here\n",
    "    batch_size = 30  # Default value for batch size\n",
    "else:\n",
    "    # Argument parser for command-line execution\n",
    "    parser = argparse.ArgumentParser(description='Argument Parser')\n",
    "    parser.add_argument(\"-sub\", \"--sub\", help=\"Subject Number\", default=7)\n",
    "    parser.add_argument(\"-bs\", \"--bs\", help=\"Batch Size\", default=30)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set the subject number and ensure it's valid\n",
    "    sub = int(args.sub)\n",
    "    assert sub in [1, 2, 5, 7]  # Validate allowed subject numbers\n",
    "\n",
    "    # Set the batch size\n",
    "    batch_size = int(args.bs)\n",
    "\n",
    "# Print status messages\n",
    "print('Libraries imported')\n",
    "print(f'Using Subject Number: {sub}')\n",
    "print(f'Using Batch Size: {batch_size}')\n"
   ],
   "id": "81f7d3582fb3d52c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n",
      "Using Subject Number: 1\n",
      "Using Batch Size: 30\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:32:29.448169Z",
     "start_time": "2025-04-08T14:32:29.444499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the path has been added\n",
    "print(\"Current sys.path:\", sys.path)\n"
   ],
   "id": "498c8e2613616a18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sys.path: ['C:\\\\Users\\\\sOrOush\\\\SoroushProjects\\\\14_CLIP_Ozcelic', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python-ce\\\\helpers\\\\pydev', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\python312.zip', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\DLLs', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question', '', 'C:\\\\Users\\\\sOrOush\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'C:/Users/sOrOush/SoroushProjects/02_Linearity_Project/02_Models/vdvae']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:33:02.663607Z",
     "start_time": "2025-04-08T14:33:02.657359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Check if the file exists\n",
    "model_path = r'C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-model-ema.th'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"The file exists: {model_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {model_path}\")\n"
   ],
   "id": "8b14ef7b7946506a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists: C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-model-ema.th\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:33:15.373342Z",
     "start_time": "2025-04-08T14:33:14.072321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Define the configuration dictionary\n",
    "H = {\n",
    "    'image_size': 64, 'image_channels': 3, 'seed': 0, 'port': 29500, 'save_dir': './saved_models/test',\n",
    "    'data_root': './', 'desc': 'test', 'hparam_sets': 'imagenet64',\n",
    "    'restore_path': r'C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-model.th',\n",
    "    'restore_ema_path': r'C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-model-ema.th',\n",
    "    'restore_log_path': r'C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-log.jsonl',\n",
    "    'restore_optimizer_path': r'C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-opt.th',\n",
    "    'dataset': 'imagenet64', 'ema_rate': 0.999, 'enc_blocks': '64x11,64d2,32x20,32d2,16x9,16d2,8x8,8d2,4x7,4d4,1x5',\n",
    "    'dec_blocks': '1x2,4m1,4x3,8m4,8x7,16m8,16x15,32m16,32x31,64m32,64x12', 'zdim': 16, 'width': 512,\n",
    "    'custom_width_str': '', 'bottleneck_multiple': 0.25, 'no_bias_above': 64, 'scale_encblock': False,\n",
    "    'test_eval': True, 'warmup_iters': 100, 'num_mixtures': 10, 'grad_clip': 220.0, 'skip_threshold': 380.0,\n",
    "    'lr': 0.00015, 'lr_prior': 0.00015, 'wd': 0.01, 'wd_prior': 0.0, 'num_epochs': 10000, 'n_batch': 4,\n",
    "    'adam_beta1': 0.9, 'adam_beta2': 0.9, 'temperature': 1.0, 'iters_per_ckpt': 25000, 'iters_per_print': 1000,\n",
    "    'iters_per_save': 10000, 'iters_per_images': 10000, 'epochs_per_eval': 1, 'epochs_per_probe': None,\n",
    "    'epochs_per_eval_save': 1, 'num_images_visualize': 8, 'num_variables_visualize': 6, 'num_temperatures_visualize': 3,\n",
    "    'mpi_size': 1, 'local_rank': 0, 'rank': 0, 'logdir': './saved_models/test/log'\n",
    "}\n",
    "\n",
    "# Dot notation for dictionary\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "H = dotdict(H)\n",
    "\n",
    "# Assuming `set_up_data` and `load_vaes` functions are defined elsewhere\n",
    "H, preprocess_fn = set_up_data(H)\n",
    "\n",
    "print('Model is Loading')\n",
    "ema_vae = load_vaes(H)\n",
    "\n",
    "# Dataset class for external images\n",
    "class batch_generator_external_images(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.im = np.load(data_path).astype(np.uint8)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.fromarray(self.im[idx])\n",
    "        img = T.functional.resize(img, (64, 64))\n",
    "        img = torch.tensor(np.array(img)).float()\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im)\n"
   ],
   "id": "a5f5032edf3823e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Loading\n",
      "Restoring ema vae from C:\\Users\\sOrOush\\SoroushProjects\\02_Linearity_Project\\02_Models\\vdvae\\model\\imagenet64-iter-1600000-model-ema.th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/sOrOush/SoroushProjects/02_Linearity_Project/02_Models/vdvae\\train_helpers.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(distributed_maybe_download(path, local_rank, mpi_size), map_location='cpu' if map_cpu else None)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:35:09.152902Z",
     "start_time": "2025-04-08T14:35:09.149021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "# Append the desired path to sys.path\n",
    "sub = 1  # Replace with the appropriate subject number if needed\n",
    "sys.path.append(r\"C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\")\n",
    "\n",
    "print(\"Updated sys.path:\", sys.path)\n"
   ],
   "id": "2830893b3ebb6312",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated sys.path: ['C:\\\\Users\\\\sOrOush\\\\SoroushProjects\\\\14_CLIP_Ozcelic', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python-ce\\\\helpers\\\\pydev', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.3.2\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\python312.zip', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\DLLs', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question', '', 'C:\\\\Users\\\\sOrOush\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\sOrOush\\\\.conda\\\\envs\\\\linearity_question\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'C:/Users/sOrOush/SoroushProjects/02_Linearity_Project/02_Models/vdvae', 'C:\\\\Users\\\\sOrOush\\\\SoroushProjects\\\\02_Linearity_Project\\\\00_DataSet\\\\processed_data\\\\subj01', 'C:\\\\Users\\\\sOrOush\\\\SoroushProjects\\\\01_Soroush_and_Shakiba\\\\NSD_High_Dimensional_Data\\\\11_Marco_And_Soroush\\\\Data\\\\processed_nsddata']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:35:44.008086Z",
     "start_time": "2025-04-08T14:35:44.004271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Display the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)\n"
   ],
   "id": "5edc0ef184308c81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\scripts\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:37:21.995842Z",
     "start_time": "2025-04-08T14:37:21.991486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the image path\n",
    "sub = 1  # Replace with the appropriate subject number\n",
    "image_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj{sub:02d}\\nsd_test_stim_sub{sub}.npy\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"The file exists: {image_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {image_path}\")\n"
   ],
   "id": "932620896f454b4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj{sub:02d}\\nsd_test_stim_sub{sub}.npy\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:09:47.758607Z",
     "start_time": "2025-04-08T16:09:47.754565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the image path\n",
    "sub = 1  # Replace with the appropriate subject number\n",
    "image_path = rf\"C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj{sub:02d}\\nsd_train_stim_sub{sub}.npy\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"The file exists: {image_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {image_path}\")\n"
   ],
   "id": "ae02ee6615ddb23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists: C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj01\\nsd_train_stim_sub1.npy\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:57:08.832176Z",
     "start_time": "2025-04-08T14:57:08.716154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear the CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# If you have variables holding GPU tensors, delete them\n",
    "# For example:\n",
    "# del model, optimizer, data_loader  # Replace with your variables\n",
    "# gc.collect()  # Re-run garbage collection after deletion\n",
    "\n",
    "# Check if VRAM is cleared\n",
    "print(\"GPU memory usage after cleanup:\")\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved()} bytes\")\n"
   ],
   "id": "ed41a6f79e65cb7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory usage after cleanup:\n",
      "Allocated: 500083200 bytes\n",
      "Cached: 530579456 bytes\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:57:16.383795Z",
     "start_time": "2025-04-08T14:57:16.377903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_properties():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No GPU available. Please ensure CUDA is installed and a GPU is accessible.\")\n",
    "        return None\n",
    "\n",
    "    gpu_properties = torch.cuda.get_device_properties(0)\n",
    "    print(f\"GPU Name: {gpu_properties.name}\")\n",
    "    print(f\"Total VRAM: {gpu_properties.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "    print(f\"Device Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Device Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "\n",
    "    return gpu_properties\n",
    "\n",
    "def suggest_batch_size(vram_gb, model_size_gb=4, buffer_size_gb=1):\n",
    "    \"\"\"\n",
    "    Suggests a batch size based on available VRAM.\n",
    "\n",
    "    Parameters:\n",
    "        vram_gb (float): Total GPU memory in GB.\n",
    "        model_size_gb (float): Approximate size of the model in memory in GB.\n",
    "        buffer_size_gb (float): Reserved space for overheads (activations, caching).\n",
    "\n",
    "    Returns:\n",
    "        int: Suggested batch size.\n",
    "    \"\"\"\n",
    "    usable_vram = vram_gb - (model_size_gb + buffer_size_gb)\n",
    "    if usable_vram <= 0:\n",
    "        print(\"Insufficient GPU memory for the model and overheads.\")\n",
    "        return 1\n",
    "\n",
    "    # Assume each data sample requires ~0.01 GB (10 MB) as a heuristic\n",
    "    batch_size = int(usable_vram / 0.01)\n",
    "    return batch_size\n",
    "\n",
    "# Get GPU properties\n",
    "gpu_props = get_gpu_properties()\n",
    "\n",
    "if gpu_props:\n",
    "    # Suggest batch size\n",
    "    total_vram_gb = gpu_props.total_memory / 1e9  # Convert bytes to GB\n",
    "    recommended_batch_size = suggest_batch_size(total_vram_gb)\n",
    "\n",
    "    print(f\"Recommended Batch Size: {recommended_batch_size}\")\n"
   ],
   "id": "b72d8c2d8148ea09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "Total VRAM: 12.88 GB\n",
      "Compute Capability: 8.9\n",
      "Device Memory Allocated: 0.50 GB\n",
      "Device Memory Cached: 0.53 GB\n",
      "Recommended Batch Size: 787\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:57:39.456761Z",
     "start_time": "2025-04-08T14:57:39.451302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def process_latents(trainloader, testloader, num_latents, batch_size, ema_vae, preprocess_fn):\n",
    "    train_latents = []\n",
    "    test_latents = []\n",
    "    ref_latent = None\n",
    "\n",
    "    # Process training data\n",
    "    for i, x in enumerate(trainloader):\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        with torch.no_grad():\n",
    "            print(f\"Processing training batch {i*batch_size}\")\n",
    "            activations = ema_vae.encoder.forward(data_input)\n",
    "            px_z, stats = ema_vae.decoder.forward(activations, get_latents=True)\n",
    "            batch_latent = []\n",
    "            for j in range(num_latents):\n",
    "                batch_latent.append(stats[j]['z'].cpu().numpy().reshape(len(data_input), -1))\n",
    "            train_latents.append(np.hstack(batch_latent))\n",
    "\n",
    "    # Process test data\n",
    "    for i, x in enumerate(testloader):\n",
    "        data_input, _ = preprocess_fn(x)\n",
    "        with torch.no_grad():\n",
    "            print(f\"Processing test batch {i*batch_size}\")\n",
    "            activations = ema_vae.encoder.forward(data_input)\n",
    "            px_z, stats = ema_vae.decoder.forward(activations, get_latents=True)\n",
    "            if i == 0:\n",
    "                ref_latent = stats\n",
    "            batch_latent = []\n",
    "            for j in range(num_latents):\n",
    "                batch_latent.append(stats[j]['z'].cpu().numpy().reshape(len(data_input), -1))\n",
    "            test_latents.append(np.hstack(batch_latent))\n",
    "\n",
    "    return (np.concatenate(train_latents),\n",
    "            np.concatenate(test_latents),\n",
    "            ref_latent)\n"
   ],
   "id": "853f33d2a9d0d364",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:18:06.768502Z",
     "start_time": "2025-04-08T16:11:14.634172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    sub = 1  # Replace with desired subject number\n",
    "    batch_size = 30  # Updated batch size\n",
    "    latent_sizes = [31]  # Updated latent sizes list\n",
    "\n",
    "    # Load data\n",
    "    train_image_path = r'C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj{:02d}\\nsd_train_stim_sub{}.npy'.format(sub, sub)\n",
    "    test_image_path = r'C:\\Users\\sOrOush\\SoroushProjects\\01_Soroush_and_Shakiba\\NSD_High_Dimensional_Data\\11_Marco_And_Soroush\\Data\\processed_nsddata\\subj{:02d}\\nsd_test_stim_sub{}.npy'.format(sub, sub)\n",
    "\n",
    "    train_images = batch_generator_external_images(data_path=train_image_path)\n",
    "    test_images = batch_generator_external_images(data_path=test_image_path)\n",
    "\n",
    "    trainloader = DataLoader(train_images, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_images, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Process each latent size\n",
    "    for num_latents in latent_sizes:\n",
    "        print(f\"\\nProcessing {num_latents} latent spaces...\")\n",
    "\n",
    "        # Create directory\n",
    "        dir_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\results\\extracted_fetures_{}_Layered\\subj{:02d}\".format(num_latents, sub)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        # Process and save latents\n",
    "        train_latents, test_latents, ref_latent = process_latents(\n",
    "            trainloader, testloader, num_latents, batch_size, ema_vae, preprocess_fn\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        np.savez(f\"{dir_path}\\\\nsd_vdvae_features_{num_latents}l.npz\",\n",
    "                 train_latents=train_latents,\n",
    "                 test_latents=test_latents)\n",
    "        np.savez(f\"{dir_path}/ref_latents_{num_latents}l.npz\",\n",
    "                 ref_latent=ref_latent)\n",
    "\n",
    "        print(f\"Saved latents for {num_latents} layers\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "75fdecce75765107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 31 latent spaces...\n",
      "Processing training batch 0\n",
      "Processing training batch 30\n",
      "Processing training batch 60\n",
      "Processing training batch 90\n",
      "Processing training batch 120\n",
      "Processing training batch 150\n",
      "Processing training batch 180\n",
      "Processing training batch 210\n",
      "Processing training batch 240\n",
      "Processing training batch 270\n",
      "Processing training batch 300\n",
      "Processing training batch 330\n",
      "Processing training batch 360\n",
      "Processing training batch 390\n",
      "Processing training batch 420\n",
      "Processing training batch 450\n",
      "Processing training batch 480\n",
      "Processing training batch 510\n",
      "Processing training batch 540\n",
      "Processing training batch 570\n",
      "Processing training batch 600\n",
      "Processing training batch 630\n",
      "Processing training batch 660\n",
      "Processing training batch 690\n",
      "Processing training batch 720\n",
      "Processing training batch 750\n",
      "Processing training batch 780\n",
      "Processing training batch 810\n",
      "Processing training batch 840\n",
      "Processing training batch 870\n",
      "Processing training batch 900\n",
      "Processing training batch 930\n",
      "Processing training batch 960\n",
      "Processing training batch 990\n",
      "Processing training batch 1020\n",
      "Processing training batch 1050\n",
      "Processing training batch 1080\n",
      "Processing training batch 1110\n",
      "Processing training batch 1140\n",
      "Processing training batch 1170\n",
      "Processing training batch 1200\n",
      "Processing training batch 1230\n",
      "Processing training batch 1260\n",
      "Processing training batch 1290\n",
      "Processing training batch 1320\n",
      "Processing training batch 1350\n",
      "Processing training batch 1380\n",
      "Processing training batch 1410\n",
      "Processing training batch 1440\n",
      "Processing training batch 1470\n",
      "Processing training batch 1500\n",
      "Processing training batch 1530\n",
      "Processing training batch 1560\n",
      "Processing training batch 1590\n",
      "Processing training batch 1620\n",
      "Processing training batch 1650\n",
      "Processing training batch 1680\n",
      "Processing training batch 1710\n",
      "Processing training batch 1740\n",
      "Processing training batch 1770\n",
      "Processing training batch 1800\n",
      "Processing training batch 1830\n",
      "Processing training batch 1860\n",
      "Processing training batch 1890\n",
      "Processing training batch 1920\n",
      "Processing training batch 1950\n",
      "Processing training batch 1980\n",
      "Processing training batch 2010\n",
      "Processing training batch 2040\n",
      "Processing training batch 2070\n",
      "Processing training batch 2100\n",
      "Processing training batch 2130\n",
      "Processing training batch 2160\n",
      "Processing training batch 2190\n",
      "Processing training batch 2220\n",
      "Processing training batch 2250\n",
      "Processing training batch 2280\n",
      "Processing training batch 2310\n",
      "Processing training batch 2340\n",
      "Processing training batch 2370\n",
      "Processing training batch 2400\n",
      "Processing training batch 2430\n",
      "Processing training batch 2460\n",
      "Processing training batch 2490\n",
      "Processing training batch 2520\n",
      "Processing training batch 2550\n",
      "Processing training batch 2580\n",
      "Processing training batch 2610\n",
      "Processing training batch 2640\n",
      "Processing training batch 2670\n",
      "Processing training batch 2700\n",
      "Processing training batch 2730\n",
      "Processing training batch 2760\n",
      "Processing training batch 2790\n",
      "Processing training batch 2820\n",
      "Processing training batch 2850\n",
      "Processing training batch 2880\n",
      "Processing training batch 2910\n",
      "Processing training batch 2940\n",
      "Processing training batch 2970\n",
      "Processing training batch 3000\n",
      "Processing training batch 3030\n",
      "Processing training batch 3060\n",
      "Processing training batch 3090\n",
      "Processing training batch 3120\n",
      "Processing training batch 3150\n",
      "Processing training batch 3180\n",
      "Processing training batch 3210\n",
      "Processing training batch 3240\n",
      "Processing training batch 3270\n",
      "Processing training batch 3300\n",
      "Processing training batch 3330\n",
      "Processing training batch 3360\n",
      "Processing training batch 3390\n",
      "Processing training batch 3420\n",
      "Processing training batch 3450\n",
      "Processing training batch 3480\n",
      "Processing training batch 3510\n",
      "Processing training batch 3540\n",
      "Processing training batch 3570\n",
      "Processing training batch 3600\n",
      "Processing training batch 3630\n",
      "Processing training batch 3660\n",
      "Processing training batch 3690\n",
      "Processing training batch 3720\n",
      "Processing training batch 3750\n",
      "Processing training batch 3780\n",
      "Processing training batch 3810\n",
      "Processing training batch 3840\n",
      "Processing training batch 3870\n",
      "Processing training batch 3900\n",
      "Processing training batch 3930\n",
      "Processing training batch 3960\n",
      "Processing training batch 3990\n",
      "Processing training batch 4020\n",
      "Processing training batch 4050\n",
      "Processing training batch 4080\n",
      "Processing training batch 4110\n",
      "Processing training batch 4140\n",
      "Processing training batch 4170\n",
      "Processing training batch 4200\n",
      "Processing training batch 4230\n",
      "Processing training batch 4260\n",
      "Processing training batch 4290\n",
      "Processing training batch 4320\n",
      "Processing training batch 4350\n",
      "Processing training batch 4380\n",
      "Processing training batch 4410\n",
      "Processing training batch 4440\n",
      "Processing training batch 4470\n",
      "Processing training batch 4500\n",
      "Processing training batch 4530\n",
      "Processing training batch 4560\n",
      "Processing training batch 4590\n",
      "Processing training batch 4620\n",
      "Processing training batch 4650\n",
      "Processing training batch 4680\n",
      "Processing training batch 4710\n",
      "Processing training batch 4740\n",
      "Processing training batch 4770\n",
      "Processing training batch 4800\n",
      "Processing training batch 4830\n",
      "Processing training batch 4860\n",
      "Processing training batch 4890\n",
      "Processing training batch 4920\n",
      "Processing training batch 4950\n",
      "Processing training batch 4980\n",
      "Processing training batch 5010\n",
      "Processing training batch 5040\n",
      "Processing training batch 5070\n",
      "Processing training batch 5100\n",
      "Processing training batch 5130\n",
      "Processing training batch 5160\n",
      "Processing training batch 5190\n",
      "Processing training batch 5220\n",
      "Processing training batch 5250\n",
      "Processing training batch 5280\n",
      "Processing training batch 5310\n",
      "Processing training batch 5340\n",
      "Processing training batch 5370\n",
      "Processing training batch 5400\n",
      "Processing training batch 5430\n",
      "Processing training batch 5460\n",
      "Processing training batch 5490\n",
      "Processing training batch 5520\n",
      "Processing training batch 5550\n",
      "Processing training batch 5580\n",
      "Processing training batch 5610\n",
      "Processing training batch 5640\n",
      "Processing training batch 5670\n",
      "Processing training batch 5700\n",
      "Processing training batch 5730\n",
      "Processing training batch 5760\n",
      "Processing training batch 5790\n",
      "Processing training batch 5820\n",
      "Processing training batch 5850\n",
      "Processing training batch 5880\n",
      "Processing training batch 5910\n",
      "Processing training batch 5940\n",
      "Processing training batch 5970\n",
      "Processing training batch 6000\n",
      "Processing training batch 6030\n",
      "Processing training batch 6060\n",
      "Processing training batch 6090\n",
      "Processing training batch 6120\n",
      "Processing training batch 6150\n",
      "Processing training batch 6180\n",
      "Processing training batch 6210\n",
      "Processing training batch 6240\n",
      "Processing training batch 6270\n",
      "Processing training batch 6300\n",
      "Processing training batch 6330\n",
      "Processing training batch 6360\n",
      "Processing training batch 6390\n",
      "Processing training batch 6420\n",
      "Processing training batch 6450\n",
      "Processing training batch 6480\n",
      "Processing training batch 6510\n",
      "Processing training batch 6540\n",
      "Processing training batch 6570\n",
      "Processing training batch 6600\n",
      "Processing training batch 6630\n",
      "Processing training batch 6660\n",
      "Processing training batch 6690\n",
      "Processing training batch 6720\n",
      "Processing training batch 6750\n",
      "Processing training batch 6780\n",
      "Processing training batch 6810\n",
      "Processing training batch 6840\n",
      "Processing training batch 6870\n",
      "Processing training batch 6900\n",
      "Processing training batch 6930\n",
      "Processing training batch 6960\n",
      "Processing training batch 6990\n",
      "Processing training batch 7020\n",
      "Processing training batch 7050\n",
      "Processing training batch 7080\n",
      "Processing training batch 7110\n",
      "Processing training batch 7140\n",
      "Processing training batch 7170\n",
      "Processing training batch 7200\n",
      "Processing training batch 7230\n",
      "Processing training batch 7260\n",
      "Processing training batch 7290\n",
      "Processing training batch 7320\n",
      "Processing training batch 7350\n",
      "Processing training batch 7380\n",
      "Processing training batch 7410\n",
      "Processing training batch 7440\n",
      "Processing training batch 7470\n",
      "Processing training batch 7500\n",
      "Processing training batch 7530\n",
      "Processing training batch 7560\n",
      "Processing training batch 7590\n",
      "Processing training batch 7620\n",
      "Processing training batch 7650\n",
      "Processing training batch 7680\n",
      "Processing training batch 7710\n",
      "Processing training batch 7740\n",
      "Processing training batch 7770\n",
      "Processing training batch 7800\n",
      "Processing training batch 7830\n",
      "Processing training batch 7860\n",
      "Processing training batch 7890\n",
      "Processing training batch 7920\n",
      "Processing training batch 7950\n",
      "Processing training batch 7980\n",
      "Processing training batch 8010\n",
      "Processing training batch 8040\n",
      "Processing training batch 8070\n",
      "Processing training batch 8100\n",
      "Processing training batch 8130\n",
      "Processing training batch 8160\n",
      "Processing training batch 8190\n",
      "Processing training batch 8220\n",
      "Processing training batch 8250\n",
      "Processing training batch 8280\n",
      "Processing training batch 8310\n",
      "Processing training batch 8340\n",
      "Processing training batch 8370\n",
      "Processing training batch 8400\n",
      "Processing training batch 8430\n",
      "Processing training batch 8460\n",
      "Processing training batch 8490\n",
      "Processing training batch 8520\n",
      "Processing training batch 8550\n",
      "Processing training batch 8580\n",
      "Processing training batch 8610\n",
      "Processing training batch 8640\n",
      "Processing training batch 8670\n",
      "Processing training batch 8700\n",
      "Processing training batch 8730\n",
      "Processing training batch 8760\n",
      "Processing training batch 8790\n",
      "Processing training batch 8820\n",
      "Processing training batch 8850\n",
      "Processing test batch 0\n",
      "Processing test batch 30\n",
      "Processing test batch 60\n",
      "Processing test batch 90\n",
      "Processing test batch 120\n",
      "Processing test batch 150\n",
      "Processing test batch 180\n",
      "Processing test batch 210\n",
      "Processing test batch 240\n",
      "Processing test batch 270\n",
      "Processing test batch 300\n",
      "Processing test batch 330\n",
      "Processing test batch 360\n",
      "Processing test batch 390\n",
      "Processing test batch 420\n",
      "Processing test batch 450\n",
      "Processing test batch 480\n",
      "Processing test batch 510\n",
      "Processing test batch 540\n",
      "Processing test batch 570\n",
      "Processing test batch 600\n",
      "Processing test batch 630\n",
      "Processing test batch 660\n",
      "Processing test batch 690\n",
      "Processing test batch 720\n",
      "Processing test batch 750\n",
      "Processing test batch 780\n",
      "Processing test batch 810\n",
      "Processing test batch 840\n",
      "Processing test batch 870\n",
      "Processing test batch 900\n",
      "Processing test batch 930\n",
      "Processing test batch 960\n",
      "Saved latents for 31 layers\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:28:09.868319Z",
     "start_time": "2025-04-08T16:28:09.858948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\14_CLIP_Ozcelic\\results\"\n",
    "\n",
    "layer_path = f\"{base_path}\\\\extracted_fetures_{31}_Layered\\\\subj{1:02d}\\\\nsd_vdvae_features_{31}l.npz\"\n",
    "nsd_features = np.load(layer_path)"
   ],
   "id": "22f88b2ff90a8d5b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:28:42.144356Z",
     "start_time": "2025-04-08T16:28:39.765498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_latents = nsd_features['train_latents'].astype(np.float32)\n",
    "test_latents = nsd_features['test_latents'].astype(np.float32)"
   ],
   "id": "b49f6928f1fdae7b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:28:50.221589Z",
     "start_time": "2025-04-08T16:28:50.217810Z"
    }
   },
   "cell_type": "code",
   "source": "train_latents.shape",
   "id": "994bcdeb900aa8ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8859, 91168)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5cff94f8aada8d6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
